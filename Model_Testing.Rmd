---
title: "Model_Testing"
author: "Alysha Helmrich"
date: "April 9, 2018"
output: pdf_document
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
r <- getOption("repos")
r["CRAN"] <- "http://cran.cnr.berkeley.edu/"
options(repos = r)
```

```{r Libraries, include=FALSE}
library(dplyr)
library(stats)
library(devtools)
library(ggfortify)
library(ggplot2)
library(randomForest)
library(glmnet)
library(earth)
library(ModelMetrics)
library(gam)
library(plotmo)
library(rJava)
library(bartMachine)
library(ISLR)
library(caTools)
library(neuralnet)
library(corrplot)
```

```{r Dataframe Creation, include = FALSE}
# Load complete dataset
setwd("~/Desktop/PredModel/Project")
df <- read.csv("NW_Dat.csv")
df <- na.omit(df)
model.df <- df

# Change Variables to Percents
model.df <- subset(model.df,
                   select = -c(X.1,
                               X,
                               X2011,
                               X2012,
                               X2013,
                               X2014,
                               X2015,
                               Full_FIPS,
                               County_Name,
                               State,
                               Pop,
                               Total.Vote))

model.df$Response <- model.df$Sol_by_Pop

folds = 10

west.df <- subset(model.df, Region=="West")
west.df$folds <- sample(x=1:folds,size=nrow(west.df),replace=T)
west.df <- subset(west.df, 
                   select = -c(Sol_by_Pop,
                               Region))


north.df <- subset(model.df, Region=="North")
north.df$folds <- sample(x=1:folds,size=nrow(north.df),replace=T)
north.df <- subset(north.df, 
                   select = -c(Sol_by_Pop,
                               Region))
```

```{r Variable Selection}
########################
## Variable Selection ##
########################

# Correlation Plot
par(mfrow=c(1,1))
res <- cor.mtest(select(model.df, -Region), conf.level = .99)
data.corr <- cor(select(model.df, -Region))
corrplot(data.corr, method="color", type = "upper", tl.col = "black", p.mat = res$p, sig.level = .01)
```

The response variable (Response), which is log(cumulative installation between 2005 and 2015)/log(population), shows insignificant relationships with No_Dip_Perc, No_Deg_Perc, and Associates_Perc. These are the percent of individuals with some high school but no high school diploma, some college but no degree, and an associate degree. Meanwhile, stonger positive correlations may be seen with population (Pop), median household income (House_Income), and number of NGOs (count) in the county. Moderate positive relationships include  GHI (GHI_avg.y), percent of individuals without a high school education (No_HS_Perc), percent of individuals with Bachelors or graduate degrees (Bachelors_Perc and Grad_Perc, respectively), and percent of individuals in the county who voted democratic in the 2012 election (Dem_Perc). Moderate negative correlations are seen with HS_Perc, the percent of individuals with a high school diploma, and Rep_Perc, the percent of individuals in the county who voted republican in the 2012 election. 

From this, the following predictors will be utilized in the modelling:
*Population (Pop) - Increased population indicates that the area may be more urbanized and susceptible to renewable adoptation. A partial dependency may be present with political leaning.*
*Income (House_Income) - Areas with more wealth are likely to have the economic power to invest in renewable energy; therefore, median household income will test this.*
*NGO Count (count) - A higher presence of environmental NGOs in a county indicates that the environmental movement has a higher agenda in the local area.*
*Solar Radiation (GHI_avg.y) - Individuals in sunnier areas may be more likely to install renewable energy as they feel it will perform efficiently.*
*Education (HS_Perc) - The education levels of the county may affect the level of renewable energy investment. HS_Perc had the strongest correlation of all the education predictors, so it will be utilized.*
*Political Leaning (Dem_Perc) - The percentage a county leans democractic will determine whether it is of red or blue influences. Democractic leanings are expected to have more renewable energy adoptation.*

```{r Variable Selection Dataframe}
# model.df <- subset(model.df, 
#                    select = c(Response,
#                               Pop,
#                               count,
#                               GHI_avg.y,
#                               HS_Perc,
#                               Dem_Perc,
#                               folds))
```


The dataset will be tested on the following models through a k-fold cross validation loop:
*linear regression*
*ridge regression*
*LASSO regression*
*general additive model*
*random forest*
*MARS/EARTH*
*bartMachine*
*neural nets*

```{r CV Model Selection, message = FALSE, results = "hide"}
######################
## Cross-Validation ##
## Model Selections ##
######################

# The dataset has already been sectioned into ten folds; 
# therefore, we will create a table to record the errors of each fold for each model.

Solar_CV <- function(dataframe, folds) {
error.df <- data.frame(null=numeric(folds),
                       linear=numeric(folds),
                       ridge=numeric(folds),
                       lasso=numeric(folds),
                       gam=numeric(folds),
                       rf=numeric(folds),
                       earth=numeric(folds),
                       bart=numeric(folds),
                       nn=numeric(folds))

# Next, the loop function will be created.

for (i in 1:folds) {
  # Create Testing and Training Data
  test_i <- which(dataframe$folds == i, arr.ind = TRUE)
  train_xy <- dataframe[-test_i, ]
  test_xy <- dataframe[test_i, ]
  
  ######################
  ## Model Selections ##
  ######################
  
  # Null
  data.null <- mean(dataframe$Response)
  error.df$null[i] <- rmse(actual = test_xy$Response, predicted = data.null)
  
  # Linear
  data.lm <- lm(Response ~ ., data = train_xy)
  lm.model.test <- predict(data.lm, test_xy)
  error.df$linear[i] <- rmse(actual = test_xy$Response, predicted = lm.model.test)
  
  # Ridge
  ytrain <- as.matrix(train_xy[, 14])
  xtrain <- as.matrix(cbind(train_xy[, 1:13]))
  data.ridge <- glmnet(x = xtrain, y = ytrain, family = "gaussian", alpha = 0)
  ytest <- as.matrix(test_xy[, 14])
  xtest <- as.matrix(cbind(test_xy[, 1:13]))
  ridge.model.test <- predict(data.ridge, xtest)
  error.df$ridge[i] <- rmse(actual = test_xy$Response, predicted = ridge.model.test[, ncol(ridge.model.test)])
  
  # LASSO
  ytrain <- as.matrix(train_xy[, 14])
  xtrain <- as.matrix(cbind(train_xy[, 1:13]))
  data.lasso <- glmnet(x = xtrain, y = ytrain,  family = "gaussian",  alpha = 1)
  ytest <- as.matrix(test_xy[, 14])
  xtest <- as.matrix(cbind(test_xy[, 1:13]))
  lasso.model.test <- predict(data.lasso, xtest)
  error.df$lasso[i] <- rmse(actual = test_xy$Response, predicted = lasso.model.test[, ncol(lasso.model.test)])
  
  # General Additive Model
  data.gam <- gam(Response ~ ., data=train_xy)
  gam.model.test <- predict(data.gam, test_xy)
  error.df$gam[i] <- rmse(actual = test_xy$Response, predicted = gam.model.test)
  
  # Random Forest
  data.rf <- randomForest(Response ~ ., data = train_xy)
  rf.model.test <- predict(data.rf, test_xy)
  error.df$rf[i] <- rmse(actual = test_xy$Response, predicted = rf.model.test)
  
  # EARTH
  data.earth <- earth(Response ~ ., data = train_xy)
  earth.model.test <- predict(data.earth, test_xy)
  error.df$earth[i] <- rmse(actual = test_xy$Response, predicted = earth.model.test)
  
  # bartMachine
  data.bart <- bartMachine(X = train_xy[, 1:13], y = train_xy$Response)
  bart.model.test <- predict(data.bart, new_data = test_xy[, 1:13])
  error.df$bart[i] <- rmse(actual=test_xy$Response, predicted = bart.model.test)
  
  # Neural Nets
  scaled.df <- dataframe  
  scaled.df$Response <- scaled.df$Response # Scaled between -1 and 1
  feats <- names(scaled.df[1:13]) # Adjust columns to not include response variable
  f <- paste(feats, collapse = '+')
  f <- paste('Response ~', f)
  f <- as.formula(f)
  data.nn <- neuralnet(f, train_xy, hidden=2, linear.output=FALSE)
  nn.model.test <- compute(data.nn, test_xy[,1:13])
  error.df$nn[i] <- rmse(actual=test_xy$Response, predicted = nn.model.test$net.result)
} 
return(error.df)
}

north_rmse <- Solar_CV(north.df, 10)
west_rmse <- Solar_CV(west.df, 10)
```

Boxplots are then utilized to compare the RMSE of each model.

```{r Error Boxplots}

ggplot(gather(north_rmse, Type, RMSE) %>% filter(Type != "null"), aes(x = Type, y = RMSE)) + geom_violin()

ggplot(gather(west_rmse, Type, RMSE) %>% filter(Type != "null"), aes(x = Type, y = RMSE)) + geom_violin()
```

Upon reviewing the boxplots, _bart machine_ is chosen as the optimal model due to the relatively low RMSE and small variance.

```{r Selected Model}
######################
### Selected Model ###
######################

west_model <- bartMachine(X = west.df[, 1:13], y = west.df$Response)
north_model <- bartMachine(X = north.df[, 1:13], y = north.df$Response)

######################
### Visualizations ###
######################

par(mfrow=c(1,1))

north_pred <- predict(north_model, new_data = north.df[, 1:13])
west_pred <- predict(west_model, west.df[, 1:13])
plot(west_pred, west.df$Response)
plot(north_pred, north.df$Response)
investigate_var_importance(west_model)
investigate_var_importance(north_model)

# var_selection_by_permute(finalmodel, bottom_margin=3) # HS_Perc, count, Pop, Dem_Perc, GHI
pd_plot(north_model,"GHI_avg.y")
pd_plot(west_model,"GHI_avg.y")
pd_plot(north_model, "House_Income")
pd_plot(west_model, "House_Income")

# Final Model Metrics
r2_north <- cor(north_pred, north.df$Response)^2
r2_west <- cor(west_pred,west.df$Response)^2
nbart_rmse <- mean(north_rmse$bart)
wbart_rmse <- mean(west_rmse$bart)
```

```{r, include=FALSE}
# Save the Environment
save(list=ls(all=T),file='All_Project_Objects.Rdata')
```
